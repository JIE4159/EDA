{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are a bunch more ways to use pandas to explore some interesting datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import multiple dataframes\n",
    "drinks = pd.read_csv('https://raw.githubusercontent.com/fivethirtyeight/data/master/alcohol-consumption/drinks.csv')\n",
    "users = pd.read_table('https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user', sep='|', index_col='user_id')\n",
    "ufo = pd.read_csv('https://raw.githubusercontent.com/planetsig/ufo-reports/master/csv-data/ufo-scrubbed-geocoded-time-standardized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#UFOs doesn't have column headings so we'll need to sort that out\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one way to do that is to create a list with the column names...\n",
    "columns = ['Date', 'City', 'State', 'Country', 'Shape', 'Duration (seconds)', 'Duration (hours/mins)', 'Description', 'Date_posted', 'Latitude', 'Longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#...and specify that that list should be your column names when importing \n",
    "ufo = pd.read_csv('https://raw.githubusercontent.com/planetsig/ufo-reports/master/csv-data/ufo-scrubbed-geocoded-time-standardized.csv', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#that's better\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pandas makes it easy for you to take a look at multiple columns at once\n",
    "ufo[['City', 'State']]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#there are also a bunch of ways to slice and dice a pandas dataframe to get the information you need. (and here's a great stackoverflow page on the merits of .loc vs. .iloc: https://stackoverflow.com/questions/31593201/pandas-iloc-vs-ix-vs-loc-explanation)\n",
    "#you can slice the rows to by specifying which ones you want to see. Here we're looking at the cities in rows 3 through 6 \n",
    "ufo.loc[3:6, 'City']              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and here are the cities and states for rows three through six \n",
    "ufo.loc[3:6, ['City','State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can also do quite a bit of pre-processing in pandas\n",
    "#for example: mapping existing values to a different set of values\n",
    "users['is_male'] = users.gender.map({'F':0, 'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# when dealing with categorical data, you can also encode strings as integer values using .factorize (this automatically starts at 0)\n",
    "users.occupation.factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pandas lets you take a look at unique values in a column\n",
    "print(users.occupation.nunique())      # count the number of unique values\n",
    "users.occupation.unique()       # return what those unique values are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can also do some data cleaning using pandas, like replacing all instances of a value in a column\n",
    "#here we're capitalizing TX\n",
    "ufo.State.replace('tx', 'TX', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#often, the data that needs the most cleaning are strings. you can access string methods using 'str'\n",
    "#so let's convert every state abbreviation to upper case\n",
    "ufo.State.str.upper()                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#you can also use 'str' to query information\n",
    "#here we're checking the substrings within the 'Description' column\n",
    "ufo[ufo['Description'].str.contains('red')==True] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#you can also change information in one column based on something in another (this is particularly useful when you're doing some string cleaning)\n",
    "ufo.loc[ufo.Country == 'gb', 'State'] = \"some county idk probably the countryside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#you can also convert a string to the datetime format\n",
    "#FUN FACT: Pandas was created to help people handle stock information and that's why it has pretty gerat date time functionalities\n",
    "ufo['Date_posted'] = pd.to_datetime(ufo['Date_posted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#you can also pull out information like the year in the date time column\n",
    "ufo['Year'] = ufo.Date_posted.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#or the month\n",
    "ufo['Month'] = ufo.Date_posted.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#you can use groupby statements to split data into groups based on some criteria, apply a function to that group, then combine the results of that function into a data structure\n",
    "#in this example, we're splitting information into years and countries with UFO sightings and then counting how many sightings there were in each year-country unit\n",
    "ufo.groupby('Year').Country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what about plotting this bit of information to look at it visually?\n",
    "#we'll first take a stab at comparing countries over time\n",
    "ct_ufo = pd.crosstab(ufo.Year, ufo.Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ct_ufo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ct_ufo[:], linewidth=4.0)\n",
    "plt.legend(ct_ufo.columns)\n",
    "#change figure size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 50\n",
    "fig_size[1] = 30\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "#change font size\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#you can also sort pandas dataframes by their index\n",
    "ufo.State.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data cleaning often involves detecting duplicate rows -- here's a bunch of ways to do that\n",
    "#users.duplicated()        #True if there are duplicates\n",
    "# users.duplicated().sum()    # count of duplicates\n",
    "users[users.duplicated()]   # only show duplicates\n",
    "# users.drop_duplicates()     # drop duplicate rows\n",
    "# users.age.duplicated()      # check a single column for duplicates\n",
    "# users.duplicated(['age', 'gender', 'zip_code']).sum()   # specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and sometimes, the easiest way to get a quick idea of the data is a cross-tabulation of two Series\n",
    "pd.crosstab(users.occupation, users.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternative syntax for boolean filtering \n",
    "users.query('age < 20')                 # users[users.age < 20]\n",
    "users.query(\"age < 20 and gender=='M'\") # users[(users.age < 20) & (users.gender=='M')]\n",
    "users.query('age < 20 or age > 60')     # users[(users.age < 20) | (users.age > 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display the memory usage of a DataFrame\n",
    "ufo.info()          # total usage\n",
    "ufo.memory_usage()  # usage by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change a Series to the 'category' data type (reduces memory usage and increases performance)\n",
    "ufo['State'] = ufo.State.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# limit which rows are read when reading in a file\n",
    "pd.read_csv('drinks.csv', nrows=10)           # only read first 10 rows\n",
    "pd.read_csv('drinks.csv', skiprows=[1, 2])    # skip the first two rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write a DataFrame out to a CSV\n",
    "drinks.to_csv('drinks_updated.csv')                 # index is used as first column\n",
    "drinks.to_csv('drinks_updated.csv', index=False)    # ignore index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save a DataFrame to disk (aka 'pickle') and read it from disk (aka 'unpickle')\n",
    "drinks.to_pickle('drinks_pickle')\n",
    "pd.read_pickle('drinks_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly sample a DataFrame\n",
    "train = drinks.sample(frac=0.75, random_state=1)    # will contain 75% of the rows\n",
    "test = drinks[~drinks.index.isin(train.index)]      # will contain the other 25%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the maximum number of rows and columns printed ('None' means unlimited)\n",
    "pd.set_option('max_rows', None)     # default is 60 rows\n",
    "pd.set_option('max_columns', None)  # default is 20 columns\n",
    "print drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset options to defaults\n",
    "pd.reset_option('max_rows')\n",
    "pd.reset_option('max_columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the options temporarily (settings are restored when you exit the 'with' block)\n",
    "with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "    print drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine everything into one function that runs your most commonly used EDA calls for you\n",
    "def eda(dataframe):\n",
    "    print (\"missing values \\n\", dataframe.isnull().sum())\n",
    "    print (\"dataframe index \\n\", dataframe.index)\n",
    "    print (\"dataframe types \\n\", dataframe.dtypes)\n",
    "    print (\"dataframe shape \\n\", dataframe.shape)\n",
    "    print (\"dataframe describe \\n\", dataframe.describe())\n",
    "    for item in dataframe:\n",
    "        print (item)\n",
    "        print (dataframe[item].nunique())\n",
    "\n",
    "eda(ufo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
